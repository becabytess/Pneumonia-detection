{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi \n",
    "import os \n",
    "api = KaggleApi()\n",
    "os.environ['KAGGLE_WORKING_DIR'] = '.'\n",
    "api.authenticate()\n",
    "api.dataset_download_files('paultimothymooney/chest-xray-pneumonia', path='dataset', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'dataset/chest_xray'\n",
    "train_dir = os.path.join(data_dir,'train')\n",
    "test_dir  = os.path.join(data_dir,'test')\n",
    "val_dir   = os.path.join(data_dir,'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_dir =os.path.join(train_dir,'NORMAL')\n",
    "train_pneu_dir = os.path.join(train_dir,'PNEUMONIA')\n",
    "val_normal_dir = os.path.join(val_dir,'NORMAL')\n",
    "val_pneu_dir = os.path.join(val_dir,'PNEUMONIA')\n",
    "train_normal_images , train_pneu_images = os.listdir(train_normal_dir),os.listdir(train_pneu_dir)\n",
    "# len(train_normal_images),len(train_Pneu_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import torch \n",
    "from PIL import Image\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self,normal_dir,pneu_dir,transform):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.normal_dir = normal_dir \n",
    "        self.pneu_dir = pneu_dir\n",
    "        self.normal_images = os.listdir(normal_dir)\n",
    "        self.pneu_images = os.listdir(pneu_dir)\n",
    "\n",
    "        self.images  = [(0,normal_image) for normal_image in self.normal_images] + [(1,pneu_image) for pneu_image in self.pneu_images]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,idx):\n",
    "        label,img = self.images[idx] \n",
    "        img_path = os.path.join(self.normal_dir if label == 0 else self.pneu_dir, img)\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_normal_dir,train_pneu_dir,transform)\n",
    "val_dataset = ChestXrayDataset(val_normal_dir,val_pneu_dir,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size)\n",
    "val_dataloader = [(x,y) for x, y in  DataLoader(val_dataset,batch_size=batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=model.fc.in_features, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 1)\n",
    ")\n",
    "\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([len(train_normal_images)/len(train_pneu_images)],dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "criterion  = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(),lr=lr,weight_decay=1e-5)\n",
    "epochs = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/100 , Batch: 1 , Loss : 0.6453663110733032 , Val loss: 0.4507593512535095\n",
      "Epoch : 0/100 , Batch: 2 , Loss : 0.665534496307373 , Val loss: 0.4880267381668091\n",
      "Epoch : 0/100 , Batch: 3 , Loss : 0.6878052353858948 , Val loss: 0.5126184225082397\n",
      "Epoch : 0/100 , Batch: 4 , Loss : 0.6490633487701416 , Val loss: 0.5098622441291809\n",
      "Epoch : 0/100 , Batch: 5 , Loss : 0.6685536503791809 , Val loss: 0.47380125522613525\n",
      "Epoch : 0/100 , Batch: 6 , Loss : 0.6851694583892822 , Val loss: 0.4585728645324707\n",
      "Epoch : 0/100 , Batch: 7 , Loss : 0.7086092233657837 , Val loss: 0.46598881483078003\n",
      "Epoch : 0/100 , Batch: 8 , Loss : 0.6378028988838196 , Val loss: 0.4766787886619568\n",
      "Epoch : 0/100 , Batch: 9 , Loss : 0.6390016078948975 , Val loss: 0.4996042251586914\n",
      "Epoch : 0/100 , Batch: 10 , Loss : 0.6701545715332031 , Val loss: 0.518699049949646\n",
      "Epoch : 0/100 , Batch: 11 , Loss : 0.6691068410873413 , Val loss: 0.5051045417785645\n",
      "Epoch : 0/100 , Batch: 12 , Loss : 0.6425657272338867 , Val loss: 0.504904568195343\n",
      "Epoch : 0/100 , Batch: 13 , Loss : 0.6103674173355103 , Val loss: 0.4870067834854126\n",
      "Epoch : 0/100 , Batch: 14 , Loss : 0.6382739543914795 , Val loss: 0.48210299015045166\n",
      "Epoch : 0/100 , Batch: 15 , Loss : 0.6424617767333984 , Val loss: 0.4727481007575989\n",
      "Epoch : 0/100 , Batch: 16 , Loss : 0.6290915012359619 , Val loss: 0.47079968452453613\n",
      "Epoch : 0/100 , Batch: 17 , Loss : 0.6368778347969055 , Val loss: 0.4505416750907898\n",
      "Epoch : 0/100 , Batch: 18 , Loss : 0.6446484327316284 , Val loss: 0.43749088048934937\n",
      "Epoch : 0/100 , Batch: 19 , Loss : 0.6161163449287415 , Val loss: 0.42378008365631104\n",
      "Epoch : 0/100 , Batch: 20 , Loss : 0.601754903793335 , Val loss: 0.4196178913116455\n",
      "Epoch : 0/100 , Batch: 21 , Loss : 0.64790940284729 , Val loss: 0.4241622984409332\n",
      "Epoch : 0/100 , Batch: 22 , Loss : 0.5791076421737671 , Val loss: 0.42676159739494324\n",
      "Epoch : 0/100 , Batch: 23 , Loss : 0.5737256407737732 , Val loss: 0.4510670006275177\n",
      "Epoch : 0/100 , Batch: 24 , Loss : 0.6163057684898376 , Val loss: 0.447979599237442\n",
      "Epoch : 0/100 , Batch: 25 , Loss : 0.6346666812896729 , Val loss: 0.44268181920051575\n",
      "Epoch : 0/100 , Batch: 26 , Loss : 0.5980355143547058 , Val loss: 0.4455215036869049\n",
      "Epoch : 0/100 , Batch: 27 , Loss : 0.5885381698608398 , Val loss: 0.44007667899131775\n",
      "Epoch : 0/100 , Batch: 28 , Loss : 0.6053577661514282 , Val loss: 0.4137856960296631\n",
      "Epoch : 0/100 , Batch: 29 , Loss : 0.598071813583374 , Val loss: 0.39641883969306946\n",
      "Epoch : 0/100 , Batch: 30 , Loss : 0.5813965201377869 , Val loss: 0.3683314621448517\n",
      "Epoch : 0/100 , Batch: 31 , Loss : 0.5905659198760986 , Val loss: 0.3706298768520355\n",
      "Epoch : 0/100 , Batch: 32 , Loss : 0.6115779280662537 , Val loss: 0.33317315578460693\n",
      "Epoch : 0/100 , Batch: 33 , Loss : 0.5844637155532837 , Val loss: 0.3429599106311798\n",
      "Epoch : 0/100 , Batch: 34 , Loss : 0.583808422088623 , Val loss: 0.3584723472595215\n",
      "Epoch : 0/100 , Batch: 35 , Loss : 0.5437792539596558 , Val loss: 0.3731120228767395\n",
      "Epoch : 0/100 , Batch: 36 , Loss : 0.5594533681869507 , Val loss: 0.3833601474761963\n",
      "Epoch : 0/100 , Batch: 37 , Loss : 0.549885094165802 , Val loss: 0.387448787689209\n",
      "Epoch : 0/100 , Batch: 38 , Loss : 0.5463510751724243 , Val loss: 0.43196964263916016\n",
      "Epoch : 0/100 , Batch: 39 , Loss : 0.5568398237228394 , Val loss: 0.433182954788208\n",
      "Epoch : 0/100 , Batch: 40 , Loss : 0.5744101405143738 , Val loss: 0.4158587157726288\n",
      "Epoch : 0/100 , Batch: 41 , Loss : 0.572462797164917 , Val loss: 0.3794357180595398\n",
      "Epoch : 0/100 , Batch: 42 , Loss : 0.49951833486557007 , Val loss: 0.34347930550575256\n",
      "Epoch : 0/100 , Batch: 43 , Loss : 0.32168489694595337 , Val loss: 0.3337988555431366\n",
      "Epoch : 0/100 , Batch: 44 , Loss : 0.34945598244667053 , Val loss: 0.34745901823043823\n",
      "Epoch : 0/100 , Batch: 45 , Loss : 0.33938997983932495 , Val loss: 0.36496567726135254\n",
      "Epoch : 0/100 , Batch: 46 , Loss : 0.32867151498794556 , Val loss: 0.38217979669570923\n",
      "Epoch : 0/100 , Batch: 47 , Loss : 0.3568527102470398 , Val loss: 0.3811624050140381\n",
      "Epoch : 0/100 , Batch: 48 , Loss : 0.3376427888870239 , Val loss: 0.37598446011543274\n",
      "Epoch : 0/100 , Batch: 49 , Loss : 0.32902923226356506 , Val loss: 0.3741445541381836\n",
      "Epoch : 0/100 , Batch: 50 , Loss : 0.33315402269363403 , Val loss: 0.361447811126709\n",
      "Epoch : 0/100 , Batch: 51 , Loss : 0.3403538465499878 , Val loss: 0.35608500242233276\n",
      "Epoch : 0/100 , Batch: 52 , Loss : 0.35161063075065613 , Val loss: 0.3528187572956085\n",
      "Epoch : 0/100 , Batch: 53 , Loss : 0.3275431990623474 , Val loss: 0.35324275493621826\n",
      "Epoch : 0/100 , Batch: 54 , Loss : 0.3443605899810791 , Val loss: 0.35565412044525146\n",
      "Epoch : 0/100 , Batch: 55 , Loss : 0.32897457480430603 , Val loss: 0.35835668444633484\n",
      "Epoch : 0/100 , Batch: 56 , Loss : 0.3428056538105011 , Val loss: 0.3672400712966919\n",
      "Epoch : 0/100 , Batch: 57 , Loss : 0.3471868634223938 , Val loss: 0.3797798454761505\n",
      "Epoch : 0/100 , Batch: 58 , Loss : 0.3152565360069275 , Val loss: 0.3880079984664917\n",
      "Epoch : 0/100 , Batch: 59 , Loss : 0.3399922549724579 , Val loss: 0.39412468671798706\n",
      "Epoch : 0/100 , Batch: 60 , Loss : 0.31208744645118713 , Val loss: 0.39614593982696533\n",
      "Epoch : 0/100 , Batch: 61 , Loss : 0.3116171360015869 , Val loss: 0.39451080560684204\n",
      "Epoch : 0/100 , Batch: 62 , Loss : 0.32000184059143066 , Val loss: 0.3982047438621521\n",
      "Epoch : 0/100 , Batch: 63 , Loss : 0.3149571716785431 , Val loss: 0.3997272849082947\n",
      "Epoch : 0/100 , Batch: 64 , Loss : 0.3056075870990753 , Val loss: 0.4006577730178833\n",
      "Epoch : 0/100 , Batch: 65 , Loss : 0.3050559163093567 , Val loss: 0.4022104740142822\n",
      "Epoch : 0/100 , Batch: 66 , Loss : 0.3199504613876343 , Val loss: 0.40018516778945923\n",
      "Epoch : 0/100 , Batch: 67 , Loss : 0.3143037259578705 , Val loss: 0.4003757834434509\n",
      "Epoch : 0/100 , Batch: 68 , Loss : 0.30723464488983154 , Val loss: 0.4021989107131958\n",
      "Epoch : 0/100 , Batch: 69 , Loss : 0.31749799847602844 , Val loss: 0.3987298607826233\n",
      "Epoch : 0/100 , Batch: 70 , Loss : 0.32235950231552124 , Val loss: 0.397197961807251\n",
      "Epoch : 0/100 , Batch: 71 , Loss : 0.2940300405025482 , Val loss: 0.39929020404815674\n",
      "Epoch : 0/100 , Batch: 72 , Loss : 0.31553930044174194 , Val loss: 0.3977782428264618\n",
      "Epoch : 0/100 , Batch: 73 , Loss : 0.29901206493377686 , Val loss: 0.39436542987823486\n",
      "Epoch : 0/100 , Batch: 74 , Loss : 0.30668163299560547 , Val loss: 0.3931363523006439\n",
      "Epoch : 0/100 , Batch: 75 , Loss : 0.3074325621128082 , Val loss: 0.3929870128631592\n",
      "Epoch : 0/100 , Batch: 76 , Loss : 0.3022722601890564 , Val loss: 0.3971197009086609\n",
      "Epoch : 0/100 , Batch: 77 , Loss : 0.30782121419906616 , Val loss: 0.4028088450431824\n",
      "Epoch : 0/100 , Batch: 78 , Loss : 0.30382436513900757 , Val loss: 0.40686866641044617\n",
      "Epoch : 0/100 , Batch: 79 , Loss : 0.3053942322731018 , Val loss: 0.4125610589981079\n",
      "Epoch : 0/100 , Batch: 80 , Loss : 0.2998313307762146 , Val loss: 0.4184136688709259\n",
      "Epoch : 0/100 , Batch: 81 , Loss : 0.2949405908584595 , Val loss: 0.4221494197845459\n",
      "Epoch : 0/100 , Batch: 82 , Loss : 0.2857629954814911 , Val loss: 0.42700129747390747\n",
      "Epoch : 0/100 , Batch: 83 , Loss : 0.29999950528144836 , Val loss: 0.42739200592041016\n",
      "Epoch : 0/100 , Batch: 84 , Loss : 0.2878914177417755 , Val loss: 0.4288069009780884\n",
      "Epoch : 0/100 , Batch: 85 , Loss : 0.2922056317329407 , Val loss: 0.43059152364730835\n",
      "Epoch : 0/100 , Batch: 86 , Loss : 0.2985924780368805 , Val loss: 0.43284761905670166\n",
      "Epoch : 0/100 , Batch: 87 , Loss : 0.29152312874794006 , Val loss: 0.4373820424079895\n",
      "Epoch : 0/100 , Batch: 88 , Loss : 0.29149141907691956 , Val loss: 0.44116076827049255\n",
      "Epoch : 0/100 , Batch: 89 , Loss : 0.30115988850593567 , Val loss: 0.44569849967956543\n",
      "Epoch : 0/100 , Batch: 90 , Loss : 0.28230535984039307 , Val loss: 0.44632643461227417\n",
      "Epoch : 0/100 , Batch: 91 , Loss : 0.2798483073711395 , Val loss: 0.44618627429008484\n",
      "Epoch : 0/100 , Batch: 92 , Loss : 0.2953495383262634 , Val loss: 0.4510299861431122\n",
      "Epoch : 0/100 , Batch: 93 , Loss : 0.2691250145435333 , Val loss: 0.4523778259754181\n",
      "Epoch : 0/100 , Batch: 94 , Loss : 0.28627580404281616 , Val loss: 0.45773404836654663\n",
      "Epoch : 0/100 , Batch: 95 , Loss : 0.28625407814979553 , Val loss: 0.4575660824775696\n",
      "Epoch : 0/100 , Batch: 96 , Loss : 0.2734530568122864 , Val loss: 0.4567391276359558\n",
      "Epoch : 0/100 , Batch: 97 , Loss : 0.2730087339878082 , Val loss: 0.45622584223747253\n",
      "Epoch : 0/100 , Batch: 98 , Loss : 0.28019285202026367 , Val loss: 0.4588204324245453\n",
      "Epoch : 0/100 , Batch: 99 , Loss : 0.28953003883361816 , Val loss: 0.4612392485141754\n",
      "Epoch : 0/100 , Batch: 101 , Loss : 0.2842131555080414 , Val loss: 0.4651392102241516\n",
      "Epoch : 0/100 , Batch: 102 , Loss : 0.27614593505859375 , Val loss: 0.4664376676082611\n",
      "Epoch : 0/100 , Batch: 103 , Loss : 0.2764187753200531 , Val loss: 0.468853235244751\n",
      "Epoch : 0/100 , Batch: 104 , Loss : 0.2732311189174652 , Val loss: 0.46743959188461304\n",
      "Epoch : 0/100 , Batch: 105 , Loss : 0.2681310772895813 , Val loss: 0.46868860721588135\n",
      "Epoch : 0/100 , Batch: 106 , Loss : 0.2691666781902313 , Val loss: 0.46747446060180664\n",
      "Epoch : 0/100 , Batch: 107 , Loss : 0.2687724828720093 , Val loss: 0.4662335216999054\n",
      "Epoch : 0/100 , Batch: 108 , Loss : 0.26726487278938293 , Val loss: 0.46703168749809265\n",
      "Epoch : 0/100 , Batch: 109 , Loss : 0.27927276492118835 , Val loss: 0.4666586220264435\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred,y)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    batch_count = 0\n",
    "    epoch_loss = 0 \n",
    "    for X,y in train_dataloader:\n",
    "        model.train()\n",
    "        batch_count += 1\n",
    "        optimizer.zero_grad()\n",
    "        X = X.to(device)\n",
    "        y = y.float().to(device)\n",
    "        y = y.unsqueeze(1)\n",
    "        y_pred = model(X).to(device)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valX,valy = random.sample(val_dataloader,1)[0]\n",
    "            valX = valX.to(device)\n",
    "            valy = valy.float().to(device)\n",
    "            valy = valy.unsqueeze(1)\n",
    "            val_preds = model(valX)\n",
    "            val_loss = criterion(val_preds,valy)\n",
    "\n",
    "        if batch_count % 100 != 0:\n",
    "            print(f'Epoch : {epoch}/{epochs} , Batch: {batch_count} , Loss : {loss.item()} , Val loss: {val_loss}')\n",
    "\n",
    "    print(f'Epoch : {epoch} , Average loss: {epoch_loss/batch_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
